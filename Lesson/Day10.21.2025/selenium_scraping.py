import time
import re
import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import os
print("Directory:", os.getcwd())
os.chdir(r"C:\Users\Admin\Desktop\PDS301m_HuongNTC2\PDS301m_HuongNTC2-\Lesson\Day10.21.2025")

# 1. Kh·ªüi t·∫°o Chrome driver
print("üöÄ ƒêang kh·ªüi t·∫°o tr√¨nh duy·ªát...")
options = Options()
options.add_argument('--headless')  # Ch·∫°y ·∫©n browser
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
options.add_argument('--disable-blink-features=AutomationControlled')
options.add_experimental_option("excludeSwitches", ["enable-automation"])
options.add_experimental_option('useAutomationExtension', False)

driver = webdriver.Chrome(options=options)
driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

# Chu·∫©n b·ªã list ƒë·ªÉ l∆∞u d·ªØ li·ªáu
all_products_data = []
html_content = None # Kh·ªüi t·∫°o bi·∫øn html_content

# 2. Truy c·∫≠p website v√† cu·ªôn trang ƒë·ªÉ load h·∫øt s·∫£n ph·∫©m
try:
    print("üîé ƒêang truy c·∫≠p website...")
    driver.get("https://nhasachphuongnam.com/van-hoc-duong-dai.html")

    # Ch·ªù trang Load ho√†n t·∫•t
    WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.TAG_NAME, "body"))
    )

    # Cu·ªôn trang ƒë·ªÉ Load t·∫•t c·∫£ s·∫£n ph·∫©m
    print("üìú ƒêang cu·ªôn trang ƒë·ªÉ load t·∫•t c·∫£ s·∫£n ph·∫©m...")
    last_height = driver.execute_script("return document.body.scrollHeight")
    
    while True:
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)  # Ch·ªù 2 gi√¢y ƒë·ªÉ n·ªôi dung m·ªõi load
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            print("...ƒê√£ cu·ªôn ƒë·∫øn cu·ªëi trang.")
            break
        last_height = new_height

    # L·∫•y HTML content sau khi ƒë√£ load h·∫øt
    html_content = driver.page_source
    print("‚úÖ ƒê√£ l·∫•y HTML content th√†nh c√¥ng.")

finally:
    driver.quit()
    print("üí® ƒê√£ ƒë√≥ng browser.")

# 3. D√πng BeautifulSoup v·ªõi HTML ƒë√£ render
soup = BeautifulSoup(html_content, 'html.parser')

# 4. T√¨m t·∫•t c·∫£ s·∫£n ph·∫©m - ph√¢n t√≠ch c·∫•u tr√∫c HTML th·ª±c t·∫ø
print("üîÑ ƒêang ph√¢n t√≠ch s·∫£n ph·∫©m...")

# Th·ª≠ c√°c selector kh√°c nhau ƒë·ªÉ t√¨m s·∫£n ph·∫©m
products = []

# C√°ch 1: T√¨m theo class th√¥ng th∆∞·ªùng
products = soup.find_all('div', class_=re.compile(r'product|item|prod', re.I))

# C√°ch 2: N·∫øu kh√¥ng t√¨m th·∫•y, th·ª≠ t√¨m theo data-product-type
if not products:
    print("...C√°ch 1 kh√¥ng th√†nh c√¥ng, th·ª≠ C√°ch 2 (data-product-type)")
    products = soup.find_all(attrs={"data-product-type": True})

# C√°ch 3: T√¨m t·∫•t c·∫£ div/li c√≥ ch·ª©a th√¥ng tin s·∫£n ph·∫©m
if not products:
    print("...C√°ch 2 kh√¥ng th√†nh c√¥ng, th·ª≠ C√°ch 3 (selector CSS)")
    products = soup.select('div[class*="product"], li[class*="product"], div[class*="item"], li[class*="item"]')

print(f"üìä T√¨m th·∫•y {len(products)} s·∫£n ph·∫©m")

# 5. Thu th·∫≠p d·ªØ li·ªáu
for i, product in enumerate(products):
    try:
        # --- T√™n s√°ch ---
        name = "N/A"
        name_selectors = [
            product.find('h2', class_=re.compile(r'product|name|title', re.I)),
            product.find('h3', class_=re.compile(r'product|name|title', re.I)),
            product.find('a', class_=re.compile(r'product|name|title', re.I)),
            product.find(attrs={"data-product-name": True}),
            product.find('div', class_=re.compile(r'name|title', re.I)),
        ]
        for selector in name_selectors:
            if selector and selector.text.strip():
                name = selector.text.strip()
                break
        
        # --- Gi√° ---
        price = "N/A"
        price_selectors = [
            product.find('span', class_=re.compile(r'price|special', re.I)),
            product.find('div', class_=re.compile(r'price', re.I)),
            product.find(attrs={"data-price": True}),
            product.find('span', class_=re.compile(r'money|currency', re.I)),
        ]
        for selector in price_selectors:
            if selector and selector.text.strip():
                price = selector.text.strip()
                # L√†m s·∫°ch gi√°
                price = re.sub(r'\s+', ' ', price).strip()
                break

        # --- T√°c gi·∫£ ---
        author = "N/A"
        author_selectors = [
            product.find('div', class_=re.compile(r'author|writer', re.I)),
            product.find('span', class_=re.compile(r'author|writer', re.I)),
            product.find('p', class_=re.compile(r'author|writer', re.I)),
        ]
        for selector in author_selectors:
            if selector and selector.text.strip():
                author = selector.text.strip()
                break

        # --- Link chi ti·∫øt ---
        link = "N/A"
        link_selectors = [
            product.find('a', href=True),
            product.find('a', class_=re.compile(r'product|link', re.I)),
        ]
        for selector in link_selectors:
            if selector and selector.get('href'):
                href = selector['href']
                if href and not href.startswith('javascript:'):
                    link = "https://nhasachphuongnam.com" + href if not href.startswith('http') else href
                    break

        # --- H√¨nh ·∫£nh ---
        image = "N/A"
        img_selectors = [
            product.find('img', src=True),
            product.find('img', class_=re.compile(r'product|image', re.I)),
        ]
        for selector in img_selectors:
            if selector and selector.get('src'):
                img_src = selector['src']
                if img_src and not img_src.startswith('data:image'):
                    image = "https://nhasachphuongnam.com" + img_src if not img_src.startswith('http') else img_src
                    break

        # Ch·ªâ L∆∞u n·∫øu c√≥ t√™n s√°ch
        if name != "N/A":
            product_data = {
                'STT': i + 1,
                'T√™n s√°ch': name,
                'T√°c gi·∫£': author,
                'Gi√°': price,
                'Link chi ti·∫øt': link,
                'H√¨nh ·∫£nh': image
            }
            all_products_data.append(product_data)
            print(f"‚úì ƒê√£ thu th·∫≠p: {name}")
            
    except Exception as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω s·∫£n ph·∫©m {i+1}: {e}")
        continue

# 6. L∆∞u v√†o CSV
if all_products_data:
    df = pd.DataFrame(all_products_data)

    # L∆∞u file CSV
    csv_filename = 'nhasachphuongnam_vanhoc_duongdai.csv'
    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')

    print(f"\n‚úÖ ƒê√É HO√ÄN TH√ÄNH!")
    print(f"ƒê√£ thu th·∫≠p ƒë∆∞·ª£c {len(all_products_data)} s·∫£n ph·∫©m")
    print(f"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o file: {csv_filename}")

    # Hi·ªÉn th·ªã preview
    print(f"\nüìä Preview d·ªØ li·ªáu:")
    print(df.head(10).to_string(index=False))

else:
    print("\n‚ùå Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†o!")
    
    # Debug: L∆∞u HTML ƒë·ªÉ ph√¢n t√≠ch
    if html_content:
        with open('debug_page.html', 'w', encoding='utf-8') as f:
            f.write(soup.prettify())
        print("ƒê√£ l∆∞u file debug_page.html ƒë·ªÉ ph√¢n t√≠ch c·∫•u tr√∫c HTML")